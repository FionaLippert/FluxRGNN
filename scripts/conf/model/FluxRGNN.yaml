# @package model
_target_: fluxrgnn.models.FluxRGNN

name: FluxRGNN

coord_dim: 4
n_edge_attr: 6
n_env: ${len:${datasource.env_vars}}

n_hidden: 64
rnn_type: LSTM
#n_fc_layers: 2
#n_lstm_layers: 1

max_t0: ${datasource.tidx_step}
context: 24
horizon: 48
min_horizon: 1
test_horizon: 72

#epochs: 300
#batch_size: 4
lr: 3e-5
lr_schedulers:
        #- _target_: torch.optim.lr_scheduler.LinearLR
        #  _partial_: true
        #  start_factor: 1e-5
        #  end_factor: 1.0
        #  total_iters: 10
        #- _target_: torch.optim.lr_scheduler.CosineAnnealingLR
        #  _partial_: true
        #  T_max: 40
        #  eta_min: 1e-5
        #- _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
        #  _partial_: true
        #  T_0: 10
        #  T_mult: 2
        #  eta_min: 1e-5
        #- _target_: torch.optim.lr_scheduler.CyclicLR
        #  _partial_: true
        #  base_lr: 1e-5
        #  max_lr: 1e-4
        #  step_size_up: 10
        #  step_size_down: 10
        #  mode: triangular2
        #  #gamma: 0.95
        #  cycle_momentum: false
        - _target_: torch.optim.lr_scheduler.ConstantLR
          _partial_: true
          factor: 1.0
          total_iters: ${trainer.max_epochs}
lr_milestones: []
#        - 10
#        - 50
#        - 90
          #- 100 #50
optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: ${model.lr}

use_log_transform: false
log_offset: 0.1
scale: 0.001
transforms:
#  - _target_: transforms.LogTransform
#    feature: x
#    offset: ${model.log_offset}
  - _target_: transforms.Rescaling
    feature: x
    factor: ${model.scale}

  #lr_decay: 300
#lr_gamma: 1.0
#early_stopping: true
#stopping_criterion: 1e-6
#avg_window: 50
dropout_p: 0.0
teacher_forcing: 0.0
teacher_forcing_gamma: 0.95
increase_horizon_rate: 0.1
increase_horizon_start: 0

force_zeros: true
#use_encoder: true
#use_boundary_model: true
#use_uv: true
root_transformed_loss: false
#compute_fluxes: true
edge_type: hexagons # voronoi
birds_per_km2: true

regularizer_weight: 0.0

observation_model:
  _target_: fluxrgnn.models.ObservationModel

decoder:
  _target_: fluxrgnn.models.RecurrentDecoder
  rnn_type: ${model.rnn_type}
  n_hidden: ${model.n_hidden}
  n_rnn_layers: 1
  use_encoder: false #true #false
  dropout_p: ${model.dropout_p}
  #static_cell_features:
  #  coords: ${model.coord_dim}
  edge_features:
    edge_attr: ${model.n_edge_attr}
  dynamic_cell_features:
    env: ${model.n_env}

flux_model:
  _target_: fluxrgnn.models.Fluxes
  #_target_: fluxrgnn.models.NumericalFluxes
  #static_cell_features:
  #  coords: ${model.coord_dim}
  edge_features:
    edge_attr: ${model.n_edge_attr}
  dynamic_cell_features:
    env: ${model.n_env}
  n_hidden: ${model.n_hidden}
  n_fc_layers: 2
  n_graph_layers: 0
  activation:
    _target_: torch.nn.ReLU
  use_log_transform: ${model.use_log_transform}
  log_offset: ${model.log_offset}
  scale: ${model.scale}
  dropout_p: ${model.dropout_p}
  transforms: ${model.transforms}


source_sink_model:
  _target_: fluxrgnn.models.SourceSink
  #_target_: fluxrgnn.models.DeltaMLP
  #model_inputs: []
    #x: 1
    #ground_states: 1
  #static_cell_features:
    #coords: ${model.coord_dim}
  dynamic_cell_features:
    env: ${model.n_env}
  n_hidden: ${model.n_hidden}
  n_fc_layers: 1
  activation:
    _target_: torch.nn.ReLU # LeakyReLU
  use_log_transform: ${model.use_log_transform}
  log_offset: ${model.log_offset}
  scale: ${model.scale}
  dropout_p: ${model.dropout_p}
  transforms: ${model.transforms}


#initial_model:
#  _target_: fluxrgnn.models.InitialStateMLP
#  node_features:
#    coords: ${model.coord_dim}
#  dynamic_features:
#    env: ${model.n_env}
#  n_hidden: ${model.n_hidden}
#  n_fc_layers: 1
#  activation:
#    _target_: torch.nn.ReLU
#  use_log_transform: ${model.use_log_transform}
#  log_offset: ${model.log_offset}
#  scale: ${model.scale}
#  dropout_p: ${model.dropout_p}
#  transforms: ${model.transforms}

#initial_model:
#  _target_: fluxrgnn.models.ObservationCopy
#  use_log_transform: ${model.use_log_transform}
#  log_offset: ${model.log_offset}
#  scale: ${model.scale}
#  dropout_p: ${model.dropout_p}
#  transforms: ${model.transforms}

initial_model:
  _target_: fluxrgnn.models.RadarToCellInterpolation
  radar_variables:
    x: 1
  dynamic_cell_features:
    env: ${model.n_env}
  n_hidden: ${model.n_hidden}
  n_fc_layers: 1
  activation:
    _target_: torch.nn.ReLU # LeakyReLU
  dropout_p: ${model.dropout_p}

#ground_model:
#  _target_: fluxrgnn.models.InitialStateMLP
#  static_cell_features:
#    coords: ${model.coord_dim}
#  #dynamic_cell_features:
#  #  env: ${model.n_env}
#  n_hidden: ${model.n_hidden}
#  n_fc_layers: 1
#  activation:
#    _target_: torch.nn.ReLU
#  use_log_transform: ${model.use_log_transform}
#  log_offset: ${model.log_offset}
#  scale: ${model.scale}
#  dropout_p: ${model.dropout_p}
#  transforms: ${model.transforms}

  
encoder:
  _target_: fluxrgnn.models.RecurrentEncoder
  rnn_type: ${model.rnn_type}
  context: ${model.context}
  n_hidden: ${model.n_hidden}
  n_rnn_layers: 1
  dropout_p: ${model.dropout_p}
  radar2cell_model:
    #_target_: fluxrgnn.models.RadarToCellGNN
    _target_: fluxrgnn.models.RadarToCellInterpolation
    radar_variables:
      x: 1
      bird_uv: 2
    dynamic_cell_features:
      env: ${model.n_env}
    radar2cell_edge_attr: 3
    n_hidden: ${model.n_hidden}
    n_fc_layers: 1
    activation:
      _target_: torch.nn.ReLU # LeakyReLU
    dropout_p: ${model.dropout_p}
  #static_cell_features:
  #    coords: ${model.coord_dim}
  dynamic_cell_features:
    env: ${model.n_env}

boundary_model:
  _target_: fluxrgnn.models.Extrapolation

load_states_from: none
